{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd94d32d-e186-4c51-9577-dba2059d3b39",
   "metadata": {},
   "source": [
    "# Lab5: Classifying real-world images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b9bae-9aac-4da1-bd0c-aa6a35a8cd46",
   "metadata": {},
   "source": [
    "In last exercise we built a CNN to classify MNIST images. \n",
    "- We also used a callback to cancel training if a certain accuracy is reached.\n",
    "- We reshaped our training and test images in order to pass them to convolution layer.\n",
    "\n",
    "We improved the performance of classification by using convolutions which spotted features in the image. The rest of the network matched those features to the labels instead of using raw pixels and hoping for the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c1084-13c2-4fba-a283-6a9f1296e4b8",
   "metadata": {},
   "source": [
    "This technique in theory should work for images that are more complex than the fashion-mnist and mnist dataset. Here we will see if we can apply the same technique to other images. \\\n",
    "_(Images in which subject is not centered and facing in the same direction)_\n",
    "\n",
    "\n",
    "### Loading the dataset\n",
    "For this we will use horses_and_humans dataset. \n",
    "As we will not be loading the dataset through inbuilt function, we will need an easy way to load the dataset.\n",
    "\n",
    "**Tensorflow supports the use of sub-directories.**\n",
    "- If I have a master directory which contains two sub-directories called Training and Validation.\n",
    "- In each of these sub-directories, I have two folders with name horses and humans, which contain the images which we want to use.\n",
    "\n",
    "With just this, I now have a fully labelled dataset for training and testing. Because with tensorflow, I can pass these directories to something called a generator and it will auto-label these images based on directory name. This labelling is achieved using ```ImageDataGenerator``` in the ```keras``` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237b68e6-39bb-471f-a89d-a50a9e0e1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84727d97-8c4e-45e2-b6f9-a01ef5ebb425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836ee47-48f2-44e1-863c-51d4c3274fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90860419-561f-4f2a-b772-d35e811bc8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414831e-2847-433b-8801-7f31081b2f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd4de1-ae75-4eec-9422-fafa671e7bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59796544-856c-40dd-8764-8e7dcb1958f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6aada0-8d9e-449e-8418-6d8fb1f88823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2279b-5b85-4287-988a-273aa76f015f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac33c55-3d8c-4148-aada-f51e8d6dffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
